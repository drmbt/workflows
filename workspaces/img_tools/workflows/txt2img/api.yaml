name: Create an image (SDXL)
description: Generate an image from text using the classic SDXL model and trained concepts (LoRAs).
tip: |-
  Only use this tool for image generation if you are specifically asked to use Stable Diffusion (SDXL) or to use a Lora with SDXL as its base model. Otherwise you should always prefer one of the Flux models for image generation. Although lower quality, SDXL can produce artistic results with more unusual characteristics.
thumbnail: app/txt2img.png
cost_estimate: 1 * n_samples
output_type: image
resolutions: [21-9_1536x640, 16-9_1344x768, 3-2_1216x832, 4-3_1152x896, 5-4_1088x896, 1-1_1024x1024, 4-5_896x1088, 3-4_896x1152, 2-3_832x1216, 9-16_768x1344, 9-21_640x1536]
handler: comfyui
status: prod
base_model: sdxl
comfyui_output_node_id: 412
comfyui_intermediate_outputs:
  controlnet_signal: 416
parameters:
  prompt:
    type: string
    label: Prompt
    description: Image prompt
    tip: |-
      Should contain a primary subject and its action, including context like background, secondary items, color schemes, style, mood, lighting, perspective, textures, time period, and cultural elements. End with artistic medium and quality enhancers like "HD" or "masterpiece".
    required: true
    comfyui:
      node_id: 370
      field: inputs
      subfield: body
  width:
    type: integer
    label: Width
    description: Width in pixels
    tip: |-
      Default to using a resolution of at least 1 megapixel. Use landscape aspect ratio for prompts that are wide or more landscape-oriented, and portrait for taller things. When using portrait, do not exceed 1:1.5. Only do square if the user requests it.
    required: true
    default: 1024
    minimum: 256
    maximum: 2048
    visible_if: use_init_image=false
    step: 8
    comfyui:
      node_id: 7
      field: inputs
      subfield: width
  height:
    type: integer
    label: Height
    description: Height in pixels
    required: true
    default: 1024
    minimum: 256
    maximum: 2048
    visible_if: use_init_image=false
    step: 8
    comfyui:
      node_id: 7
      field: inputs
      subfield: height
  n_samples:
    type: integer
    label: Number of samples
    description: Number of samples to generate
    tip: |-
      This is the number of variations to generate for the prompt. If you get a request for n_samples > 1, you are still using a *single* prompt for the whole set.
    required: true
    default: 1
    minimum: 1
    maximum: 4
  use_lora:
    type: boolean
    label: Use custom model
    description: Activate a LoRA finetuned model
    tip: Activate this to generate using a custom, trained LoRA (SDXL) model.
    default: false
    comfyui:
      node_id: 193
      field: inputs
      subfield: value
  lora:
    type: lora
    label: LoRA
    description: Use a custom model (LoRA)
    tip: name of the custom SDXL LoRA model. Do not use Flux Loras for this tool.
    visible_if: use_lora=true
    comfyui:
      node_id: 162
      field: inputs
      subfield: lora_name
  lora_strength:
    type: float
    label: Custom model strength
    description: Strength of the LoRA model
    tip: |-
      If outputs resemble the LoRA but have low prompt adherence or all look too similar, turn down the LoRA strength. If outputs dont look enough like the training images, increase it.
    default: 0.7
    minimum: 0.0
    maximum: 1.0
    step: 0.01
    visible_if: use_lora=true
    comfyui:
      node_id: 96
      field: inputs
      subfield: value
  use_init_image:
    type: boolean
    label: Use starting image
    description: Enable image-to-image, and controlnet guidance features
    tip: |-
      This guides your content towards the init_image. If this is true, an init_image must be set. If controlnet is used, this must be true.
    default: false
    comfyui:
      node_id: 198
      field: inputs
      subfield: value
  init_image:
    type: image
    label: Starting image
    description: Initial image from which to start diffusion process
    tip: |-
      Guides the output towards the colors and general composition of the starting image. Useful for image-to-image tasks.
    visible_if: use_init_image=true
    comfyui:
      node_id: 16
      field: inputs
      subfield: image
  denoise:
    type: float
    label: Generation strength
    description: Strength of the generation process on top of the starting image
    tip: |-
      Decreasing this increases the influence of a starting image. The default of 1 is 100% AI creativity, ignoring any starting image, whereas a value of 0.5 will adhere closely to the original input. Denoise must be 1 if there is no init image, and must be less than 1 if there is one.
    default: 1.0
    minimum: 0.0
    maximum: 1.0
    step: 0.01
    visible_if: use_init_image=true
    comfyui:
      node_id: 220
      field: inputs
      subfield: value
  size_from_input:
    type: boolean
    label: Use starting image size
    description: |-
      Override the provided width and height parameters with the actual resolution of your starting image.
    default: false
    visible_if: use_init_image=true
    comfyui:
      node_id: 8
      field: inputs
      subfield: value
  enforce_SDXL_resolution:
    type: boolean
    label: Use optimized resolution
    description: Round to the nearest optimized SDXL resolution, recommended.
    default: false
    visible_if: use_init_image=true
    comfyui:
      node_id: 337
      field: inputs
      subfield: value
  use_controlnet:
    type: boolean
    label: Apply controlnet to starting image
    visible_if: use_init_image=true
    description: |-
      Apply Controlnet to guide the image towards the shape of the starting image.
    tip: |-
      Guides the output image to match the shape and structure of the starting image. Enable this when a starting image is provided and shape guidance is desired. Shape guidance refers to controlnet conditioning.
    default: false
    comfyui:
      node_id: 408
      field: inputs
      subfield: value
  preprocessor:
    type: string
    label: Controlnet preprocessor
    description: |-
      What type of shape guidance to apply. Different types have subtly different effects on the output.
    tip: |-
      Canny detects edges, good for architecture and objects. Depth creates depth maps for 3D-like images. HED provides smooth edge detection for detailed art. OpenPose detects human poses. LineArt creates line drawings for black-and-white art. Scribble converts sketches into structured inputs.
    default: canny
    choices: [none, canny, depth, scribble, pose, threshold, lineart]
    visible_if: use_controlnet=true
    comfyui:
      node_id: 283
      field: inputs
      subfield: select_item
  controlnet_strength:
    type: float
    label: Controlnet strength
    description: Strength of the shape guidance (controlnet)
    tip: |-
      0.6 is a good default, use 0.4 for subtle guidance (more freedom for the AI), and 0.8-1.0 for heavy guidance.
    default: 0.6
    minimum: 0.0
    maximum: 1.2
    step: 0.01
    visible_if: use_controlnet=true
    comfyui:
      node_id: 36
      field: inputs
      subfield: value
  use_ipadapter:
    type: boolean
    label: Use style image
    description: Apply style elements from a given image
    tip: |-
      Uses a style image to guide the composition, subjects and aesthetics of the generated image.
    default: false
    comfyui:
      node_id: 35
      field: inputs
      subfield: value
  style_image:
    type: image
    label: Style image
    description: |-
      Image of an style, texture or visual aesthetic to transfer to the image
    visible_if: use_ipadapter=true
    comfyui:
      node_id: 145
      field: inputs
      subfield: image
  ipadapter_strength:
    type: float
    label: Style strength
    description: Style transfer strength
    tip: |-
      Higher values (>0.8) will cause strong adherence to the style image, lower values (<0.4) will give more freedom to interpret the prompt.
    default: 0.8
    minimum: 0.0
    maximum: 1.5
    visible_if: use_ipadapter=true
    comfyui:
      node_id: 59
      field: inputs
      subfield: value
  SDXL_model:
    type: string
    label: SDXL Model
    description: Pick which SDXL model to use
    hide_from_agent: true
    default: Eden_SDXL.safetensors
    choices: [Eden_SDXL.safetensors, juggernautXL_version6Rundiffusion.safetensors]
    comfyui:
      node_id: 410
      field: inputs
      subfield: ckpt_name
  no_token_prompt:
    type: string
    label: Prompt without the added embedding trigger.
    description: Base user prompt without the embedding token
    hide_from_agent: true
    hide_from_ui: true
    comfyui:
      node_id: 243
      field: inputs
      subfield: value
  negative_prompt:
    type: string
    label: Negative prompt
    description: Negative text prompt, what you do *not* want to generate.
    tip: |-
      Keep this at default or at most, add to this prompt, unless specifically instructed otherwise.
    hide_from_agent: true
    default: embedding:negativeXL_D, (worst quality, low quality, normal quality:1.5)
    comfyui:
      node_id: 33
      field: inputs
      subfield: value
  seed:
    type: integer
    label: Seed
    description: Reproducibility seed.
    tip: |-
      You should only set this if you want to start from/copy the seed of a previous image. Great for redoing an image generation you like with a slightly modified prompt. Unless one is specified, you should leave this blank, and it will be randomly chosen.
    default: random
    minimum: 0
    maximum: 2147483647
    comfyui:
      node_id: 27
      field: inputs
      subfield: seed
  steps:
    type: integer
    label: Steps
    description: Diffusion steps
    tip: |-
      More steps is better, but slower. Use default unless requested otherwise.
    default: 35
    step: 1
    minimum: 10
    maximum: 50
    comfyui:
      node_id: 171
      field: inputs
      subfield: steps_total
