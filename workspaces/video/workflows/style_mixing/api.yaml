name: Style Mixing
description: Create a video from a set of style images. This is a very good tool for creating videos from multiple images.
tip: This workflow creates animations from a set of images and several other inputs. First is the motion template that controls how the content of the style images is mapped onto the video (spatially).
output_type: video
cost_estimate: 0.5 * n_frames
handler: comfyui
resolutions: [16-9_2048x1152, 3-2_1782x1024, 1-1_1024x1024, 2-3_1024x1782, 9x16_1152x2048]
comfyui_output_node_id: 106
parameters:
- name: images
  label: Style Images
  description: Style images driving the content of the generated video with IP-adapter
  type: image[]
  min_length: 1
  max_length: 6
  required: true
  comfyui: 
    node_id: 74
    field: inputs
    subfield: folder
    preprocessing: folder
- name: n_frames
  label: Frames
  description: Number of video frames to generate (12 frames = 1 second of video, although the final video will be interpolated to always be 24 fps)
  type: int
  default: 64
  minimum: 16
  maximum: 192
  comfyui: 
    node_id: 198
    field: inputs
    subfield: total_frames
- name: width
  label: Width
  description: Width of the video in number of pixels
  type: int
  default: 640
  minimum: 512
  maximum: 1024
  step: 32
  comfyui: 
    node_id: 261
    field: inputs
    subfield: width
- name: height
  label: Height
  description: Height of the video in number of pixels
  type: int
  default: 640
  minimum: 512
  maximum: 1024
  step: 32
  comfyui: 
    node_id: 261
    field: inputs
    subfield: height
- name: use_controlnet
  label: Use controlnet
  description: Apply Controlnet guidance to the video generation.
  tip: Controlnet uses image preprocessors to guide the output results towards the shape of a Guidance Image.
  type: bool
  default: false
  comfyui: 
    node_id: 273
    field: inputs
    subfield: value
- name: control_image
  label: Guidance image
  description: A guidance image used as input to controlnet. Will guide the shape of the output video.
  type: image
  visible_if: use_controlnet=true
  comfyui: 
    node_id: 117
    field: inputs
    subfield: image
- name: preprocessor
  label: Controlnet preprocessor
  description: Type of controlnet preprocessor. Make sure to match controlnet model! Examples can be seen at https://github.com/lllyasviel/ControlNet-v1-1-nightly?tab=readme-ov-file#controlnet-11-depth
  tip:  depth will recreate an approximate depth of your input scene, and is best for 3 dimensional compositions. Canny edge creates strong edge detection adherance to the shape of your image, whereas scribble will create guidance towards a rougher sketched shape of your starting image. 
  type: string
  visible_if: use_controlnet=true
  default: CannyEdgePreprocessor
  choices: [CannyEdgePreprocessor, DepthAnythingV2Preprocessor, AnyLineArtPreprocessor_aux, DensePosePreprocessor, ScribblePreprocessor]
  choices_label: [edges (canny), depth, lines (lineart), human pose, scribble lines]
  comfyui: 
    node_id: 148
    field: inputs
    subfield: preprocessor    
    remap:
      - node_id: 107
        field: inputs
        subfield: control_net_name
        value:
          - input: CannyEdgePreprocessor
            output: control_v11p_sd15_canny.pth
          - input: DepthAnythingV2Preprocessor
            output: control_v11f1p_sd15_depth.pth
          - input: AnyLineArtPreprocessor_aux
            output: control_v11p_sd15_lineart.pth
          - input: DensePosePreprocessor
            output: control_v11p_sd15_openpose.pth
          - input: ScribblePreprocessor
            output: control_v11p_sd15_scribble.pth
- name: controlnet_strength
  label: Controlnet strength
  description: set the guidance strength of the controlnet model, recommended values are 0.4-0.6
  tip: A good default is around 0.5, with ranges between 0.35-0.5 for subtle guidance, and 0.5-0.8 for something more heavy handed
  type: float
  default: 0.5
  minimum: 0.0
  maximum: 1.5
  visible_if: use_controlnet=true
  comfyui: 
    node_id: 116
    field: inputs
    subfield: strength
- name: motion_mode
  label: Motion Mode
  description: Motion mode that controls how the style images will get mapped into the video
  type: string
  choices: [horizontal_stripes, vertical_stripes, progressive_rotating_segment, rotating_segments, concentric_circles, concentric_rectangles]
  default: concentric_circles
  comfyui: 
    node_id: 198
    field: inputs
    subfield: mode
- name: invert_motion
  label: Invert Motion Mask
  description: Inverts the motion mask (moving inwards instead of outwards, up instead of down etc)
  type: bool
  hide_from_agent: true
  default: false
  comfyui: 
    node_id: 198
    field: inputs
    subfield: invert_motion
- name: motion_scale
  label: Motion Scale
  description: Motion scale for the animation, determines how much motion will be in the final video. Highly recommended to leave this at default.
  tip: The default value of 1.15 is good for most cases. Lowering to eg 0.9 will result in very subtle motion, increasing to eg 1.25 will result in more motion. Going above 1.3 is almost never desirable.
  type: float
  default: 1.15
  minimum: 0.9
  maximum: 1.35
  comfyui: 
    node_id: 30
    field: inputs
    subfield: motion_scale

- name: seed
  label: Seed
  description: Set random seed for reproducibility. If blank, will be set to a random value.
  tip: You should only set this if you want to start from/copy the seed of a previous image. Unless one is specified, you should leave this at default! 
  type: int
  default: random
  minimum: 0
  maximum: 2147483647
  comfyui: 
    node_id: 282
    field: inputs
    subfield: seed